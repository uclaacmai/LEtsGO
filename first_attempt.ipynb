{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegoDataset(Dataset):\n",
    "    \"\"\"Custom dataset class for Lego Minifigure dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, img_dir, test=False, transform=None, target_transform=None):\n",
    "        \"\"\"initialize a LegoDataset instance\n",
    "        \n",
    "        Keyword arguments:\n",
    "        img_dir -- the path to the root image directory of test and train data\n",
    "        test -- True to load test data (default: False)\n",
    "        transform -- transform to apply to X\n",
    "        target_transform -- transform to apply to y\"\"\"\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.test = test\n",
    "        self.img_dir = os.path.join(img_dir, \"test/\" if test else \"train/\")\n",
    "        self.full_df = None\n",
    "        \n",
    "        # read path names and class names from csv files\n",
    "        meta_df = pd.read_csv(os.path.join(self.img_dir, \"metadata.csv\"))\n",
    "        if self.test:\n",
    "            test_df = pd.read_csv(os.path.join(self.img_dir, \"test.csv\"))\n",
    "            self.full_df = test_df.merge(meta_df, on=\"class_id\")\n",
    "        else:\n",
    "            train_df = pd.read_csv(os.path.join(self.img_dir, \"index.csv\"))\n",
    "            self.full_df = train_df.merge(meta_df, on=\"class_id\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.full_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.full_df.iloc[idx]\n",
    "        image = read_image(os.path.join(self.img_dir, row[\"path\"])).float()\n",
    "        label = row[\"class_id\"] - 1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load datasets for getting mean and std for standardization\n",
    "def get_mean_std(size=[224, 224]):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(size)\n",
    "    ])\n",
    "    train_dataset = LegoDataset(\"data/\", test=False, transform=transform)\n",
    "\n",
    "    # get mean and std of dataset\n",
    "    loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "    data = next(iter(loader))\n",
    "    return data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for real\n",
    "input_size = [64, 64]\n",
    "mean, std = get_mean_std(input_size)\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(input_size),\n",
    "    torchvision.transforms.Normalize(mean, std)\n",
    "])\n",
    "train_dataset = LegoDataset(\"data/\", test=False, transform=transform)\n",
    "test_dataset = LegoDataset(\"data/\", test=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple conv net\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # conv_stack\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2))\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # 2 dense layers\n",
    "        self.dense_stack = nn.Sequential(\n",
    "            nn.Linear(1152, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 36)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_stack(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, optimizer, loss_fn, train_loader, test_loader, n_epochs):\n",
    "        for e in range(n_epochs):\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for X, y in train_loader:\n",
    "                # get preds\n",
    "                preds = self.forward(X)\n",
    "                loss = loss_fn(preds, y)\n",
    "                \n",
    "                # backprop\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # collect stats\n",
    "                max_preds = preds.argmax(1)\n",
    "                total += y.size()[0]\n",
    "                correct += sum(max_preds == y)\n",
    "            test_total = 0\n",
    "            test_correct = 0\n",
    "            \n",
    "            # get test acc\n",
    "            with torch.no_grad():\n",
    "                for X, y in test_loader:\n",
    "                    preds = model(X)\n",
    "                    max_preds = preds.argmax(1)\n",
    "                    test_total += y.size()[0]\n",
    "                    test_correct += sum(max_preds == y)\n",
    "            \n",
    "            train_acc = correct / total\n",
    "            test_acc = test_correct / test_total\n",
    "            # print out stats\n",
    "            print(f\"epoch: {e}\\t train_acc: {train_acc:.3f}\\t test_acc: {test_acc:.3f}\")\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv_stack): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (dense_stack): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=36, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# run everything!\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=16)\n",
    "model = ConvNet()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 36 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-713375b14f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-7817cd974fca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, optimizer, loss_fn, train_loader, test_loader, n_epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m# get preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m# backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m    962\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2466\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2468\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Target 36 is out of bounds."
     ]
    }
   ],
   "source": [
    "model.train(optimizer, loss_fn, train_loader, test_loader, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets try ResNet!\n",
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new transform\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# data aug for training\n",
    "data_aug = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomApply([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomRotation(45)\n",
    "    ]),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# data loaders\n",
    "train_dataset = LegoDataset(\"data/\", test=False, transform=data_aug)\n",
    "test_dataset = LegoDataset(\"data/\", test=True, transform=preprocess)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# disable grad for all parameters\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# replace fc layer\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, out_features=36, bias=True)\n",
    "\n",
    "# set up params to update\n",
    "params_to_update = resnet.fc.parameters()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(params_to_update, lr=0.01, momentum=0.9)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, n_epochs)\n",
    "\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    test_total = 0\n",
    "    test_correct = 0\n",
    "    \n",
    "    resnet.train()\n",
    "    for X, y in train_loader:\n",
    "        # forward pass\n",
    "        preds = resnet.forward(X)\n",
    "        loss = loss_fn(preds, y)\n",
    "        \n",
    "        # backward pass\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        # collect stats\n",
    "        preds_max = preds.argmax(1)\n",
    "        train_total += y.size()[0]\n",
    "        train_correct += sum(preds_max == y)\n",
    "    \n",
    "    # update scheduler\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    train_acc = train_correct / train_total\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    resnet.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # forward pass\n",
    "            preds = resnet.forward(X)\n",
    "\n",
    "            # collect stats\n",
    "            preds_max = preds.argmax(1)\n",
    "            test_total += y.size()[0]\n",
    "            test_correct += sum(preds_max == y)\n",
    "    \n",
    "    test_acc = test_correct / test_total\n",
    "    test_accs.append(test_acc)\n",
    "    print(f\"epoch: {e}\\t train_acc: {train_acc:.3f}\\t test_acc: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "xs = [i for i in range(n_epochs)]\n",
    "\n",
    "plt.plot(xs, train_accs, color='orange', label=\"train_acc\")\n",
    "plt.plot(xs, test_accs, color='blue', label='test_acc')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('test and train acc vs epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
