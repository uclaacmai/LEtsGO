{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LegoDataset(Dataset):\n",
    "    \"\"\"Custom dataset class for Lego Minifigure dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, img_dir, test=False, transform=None, target_transform=None):\n",
    "        \"\"\"init method.\n",
    "        \n",
    "        Keyword arguments:\n",
    "        img_dir -- the path to the root image directory of test and train data\n",
    "        test -- True to load test data (default: False)\n",
    "        transform -- transform to apply to X\n",
    "        target_transform -- transform to apply to y\"\"\"\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.test = test\n",
    "        self.img_dir = os.path.join(img_dir, \"test/\" if test else \"train/\")\n",
    "        self.full_df = None\n",
    "        \n",
    "        # read path names and class names from csv files\n",
    "        meta_df = pd.read_csv(os.path.join(self.img_dir, \"metadata.csv\"))\n",
    "        if self.test:\n",
    "            test_df = pd.read_csv(os.path.join(self.img_dir, \"test.csv\"))\n",
    "            self.full_df = test_df.merge(meta_df, on=\"class_id\")\n",
    "        else:\n",
    "            train_df = pd.read_csv(os.path.join(self.img_dir, \"index.csv\"))\n",
    "            self.full_df = train_df.merge(meta_df, on=\"class_id\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.full_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.full_df.iloc[idx]\n",
    "        image = read_image(os.path.join(self.img_dir, row[\"path\"])).float()\n",
    "        label = row[\"class_id\"] - 1\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load datasets for getting mean and std for standardization\n",
    "def get_mean_std(size=[224, 224]):\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize(size)\n",
    "    ])\n",
    "    train_dataset = LegoDataset(\"data/\", test=False, transform=transform)\n",
    "\n",
    "    # get mean and std of dataset\n",
    "    loader = DataLoader(train_dataset, batch_size=len(train_dataset))\n",
    "    data = next(iter(loader))\n",
    "    return data[0].mean(), data[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for real\n",
    "input_size = [64, 64]\n",
    "mean, std = get_mean_std(input_size)\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(input_size),\n",
    "    torchvision.transforms.Normalize(mean, std)\n",
    "])\n",
    "train_dataset = LegoDataset(\"data/\", test=False, transform=transform)\n",
    "test_dataset = LegoDataset(\"data/\", test=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple conv net\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # conv_stack\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(16, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Conv2d(32, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2))\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # 2 dense layers\n",
    "        self.dense_stack = nn.Sequential(\n",
    "            nn.Linear(1152, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 36)\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_stack(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, optimizer, loss_fn, train_loader, test_loader, n_epochs):\n",
    "        for e in range(n_epochs):\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for X, y in train_loader:\n",
    "                # get preds\n",
    "                preds = self.forward(X)\n",
    "                loss = loss_fn(preds, y)\n",
    "                \n",
    "                # backprop\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # collect stats\n",
    "                max_preds = preds.argmax(1)\n",
    "                total += y.size()[0]\n",
    "                correct += sum(max_preds == y)\n",
    "            test_total = 0\n",
    "            test_correct = 0\n",
    "            \n",
    "            # get test acc\n",
    "            with torch.no_grad():\n",
    "                for X, y in test_loader:\n",
    "                    preds = model(X)\n",
    "                    max_preds = preds.argmax(1)\n",
    "                    test_total += y.size()[0]\n",
    "                    test_correct += sum(max_preds == y)\n",
    "            \n",
    "            train_acc = correct / total\n",
    "            test_acc = test_correct / test_total\n",
    "            # print out stats\n",
    "            print(f\"epoch: {e}\\t train_acc: {train_acc:.3f}\\t test_acc: {test_acc:.3f}\")\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run everything!\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
    "test_loader = DataLoader(test_dataset, shuffle=True, batch_size=16)\n",
    "model = ConvNet()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t train_acc: 0.040\t test_acc: 0.068\n",
      "epoch: 1\t train_acc: 0.065\t test_acc: 0.041\n",
      "epoch: 2\t train_acc: 0.128\t test_acc: 0.096\n",
      "epoch: 3\t train_acc: 0.222\t test_acc: 0.123\n",
      "epoch: 4\t train_acc: 0.372\t test_acc: 0.205\n",
      "epoch: 5\t train_acc: 0.537\t test_acc: 0.178\n",
      "epoch: 6\t train_acc: 0.636\t test_acc: 0.178\n",
      "epoch: 7\t train_acc: 0.770\t test_acc: 0.247\n",
      "epoch: 8\t train_acc: 0.852\t test_acc: 0.205\n",
      "epoch: 9\t train_acc: 0.881\t test_acc: 0.233\n",
      "epoch: 10\t train_acc: 0.938\t test_acc: 0.205\n",
      "epoch: 11\t train_acc: 0.960\t test_acc: 0.247\n",
      "epoch: 12\t train_acc: 0.960\t test_acc: 0.219\n",
      "epoch: 13\t train_acc: 0.983\t test_acc: 0.301\n",
      "epoch: 14\t train_acc: 0.994\t test_acc: 0.260\n",
      "epoch: 15\t train_acc: 0.997\t test_acc: 0.247\n",
      "epoch: 16\t train_acc: 0.997\t test_acc: 0.288\n",
      "epoch: 17\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 18\t train_acc: 0.997\t test_acc: 0.274\n",
      "epoch: 19\t train_acc: 0.997\t test_acc: 0.274\n",
      "epoch: 20\t train_acc: 1.000\t test_acc: 0.315\n",
      "epoch: 21\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 22\t train_acc: 1.000\t test_acc: 0.315\n",
      "epoch: 23\t train_acc: 1.000\t test_acc: 0.288\n",
      "epoch: 24\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 25\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 26\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 27\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 28\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 29\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 30\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 31\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 32\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 33\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 34\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 35\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 36\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 37\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 38\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 39\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 40\t train_acc: 1.000\t test_acc: 0.260\n",
      "epoch: 41\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 42\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 43\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 44\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 45\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 46\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 47\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 48\t train_acc: 1.000\t test_acc: 0.274\n",
      "epoch: 49\t train_acc: 1.000\t test_acc: 0.274\n"
     ]
    }
   ],
   "source": [
    "model.train(optimizer, loss_fn, train_loader, test_loader, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
